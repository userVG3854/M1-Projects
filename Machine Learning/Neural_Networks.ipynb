{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I55GLkr4qoYi"
      },
      "source": [
        "# Classification using neural networks\n",
        "\n",
        "We study here the performance of feedforward neural networks to classify digits in the MNIST set.\n",
        "\n",
        "**There are 2 questions to answer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77CHrAbIqoYj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# set up the random number generator: given seed for reproducibility, None otherwise\n",
        "# (see https://numpy.org/doc/stable/reference/random/generator.html#numpy.random.default_rng)\n",
        "my_seed = 1\n",
        "rng = np.random.default_rng(seed=my_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea801AThqoYl"
      },
      "source": [
        "## Construction of the dataset\n",
        "\n",
        "We use the MNIST dataset already encountered in various hands-on sessions. We download it through PyTorch here (note: I had to run \"jupyter nbextension enable --py widgetsnbextension\" in the command line for this to work; maybe also \"pip3 install --upgrade ipywidgets\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KXalLDf_qoYm"
      },
      "outputs": [],
      "source": [
        "full_train_dataset = torchvision.datasets.MNIST(root='./data',train=True,transform=transforms.ToTensor(),download=True)\n",
        "full_test_dataset = torchvision.datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor(),download=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnjN6SBEqoYn"
      },
      "source": [
        "We first explore the format of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr-hC6TbqoYo",
        "outputId": "13185a1e-bd40-47a5-bbce-a7e3e632e233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "\n",
            "format of train data: torch.uint8\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data\n",
            "    Split: Test\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n",
            "\n",
            "format of test data: torch.uint8\n"
          ]
        }
      ],
      "source": [
        "print(full_train_dataset)\n",
        "print(\"\\nformat of train data:\",full_train_dataset.data.dtype)\n",
        "print(full_test_dataset)\n",
        "print(\"\\nformat of test data:\",full_train_dataset.data.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja8sV4HoqoYo"
      },
      "source": [
        "We next construct a training set and a validation set out of the full training set. In order to make the training faster, we can reduce the size of the dataset if we want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iR4-zz6sqoYp"
      },
      "outputs": [],
      "source": [
        "reduced_length = 50000\n",
        "validation_length = 10000\n",
        "# check whether we go out of bounds in terms of use of training data points\n",
        "assert(reduced_length+validation_length<=full_train_dataset.data.shape[0])\n",
        "# we can then extract the corresponding indices\n",
        "indices_train = range(reduced_length)\n",
        "indices_validation = range(reduced_length,reduced_length+validation_length)\n",
        "train_dataset = torch.utils.data.Subset(full_train_dataset, indices=indices_train)\n",
        "validation_dataset = torch.utils.data.Subset(full_train_dataset, indices=indices_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Lc5aEnqoYp"
      },
      "source": [
        "We can plot the first elements of the resulting data set in order to see what they looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "euiHl1viqoYq",
        "outputId": "a89d33ab-c632-449e-9525-f9fd690d24b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "picture_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=25,shuffle=True)\n",
        "examples = iter(picture_loader)\n",
        "example_data, example_labels = next(examples)\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    # color map = binary, other choices here https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
        "    plt.imshow(example_data[i][0].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.title(example_labels[i].item())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA6T9nodqoYr"
      },
      "source": [
        "## Introducing neural networks\n",
        "\n",
        "We first introduce the class of neural networks we consider. Activation functions and topology can be modified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN39NMTfqoYs"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "         super(NeuralNet, self).__init__()\n",
        "         self.input_size = input_size\n",
        "         self.relu = nn.ReLU()\n",
        "         self.layer_1 = nn.Linear(input_size, hidden_size)\n",
        "         self.layer_2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "         out = self.layer_1(x)\n",
        "         out = self.relu(out)\n",
        "         out = self.layer_2(out)\n",
        "         # no activation and no softmax at the end since the loss function requires only unnormalized logits\n",
        "         return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjKUgCOGqoYt"
      },
      "source": [
        "We next specify the parameters and loss function. See https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html for the cross entropy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWwxvcIIqoYt"
      },
      "outputs": [],
      "source": [
        "#--- construction of the model: from input_size to num_classes with one hidden layer ---\n",
        "input_size = 784\n",
        "hidden_size = 100 ## TO COMPLETE\n",
        "num_classes = 10\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "\n",
        "#--- Loss and optimizer ---\n",
        "num_epochs = 5 ## TO COMPLETE\n",
        "batch_size = 32 ## TO COMPLETE\n",
        "learning_rate = 0.01 ## TO COMPLETE\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#--- data ---\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=validation_length,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=test_dataset.data.shape[0],shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rllYc0ReqoYu"
      },
      "source": [
        "We can check that the test and validation sets consist of a single batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbqSQgaMqoYu",
        "outputId": "c610d6ce-24c5-4ed7-cc2d-d9f09d112925"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation: torch.Size([10000, 1, 28, 28])\n",
            "test: torch.Size([10000, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "for i, (images, labels) in enumerate(validation_loader):\n",
        "    print('validation:',images.shape)\n",
        "for i, (images, labels) in enumerate(test_loader):\n",
        "    print('test:',images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC5lgf0LqoYu"
      },
      "source": [
        "**Question 1.** Perform the training. What accuracy can you get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YUWoR3_qoYv",
        "outputId": "7ef51c12-0502-4dae-8c38-36a2fcae9130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Better model // saving\n",
            "Epoch [1/5], Train loss: 0.1187, Validation loss: 0.1626\n",
            "-- Better model // saving\n",
            "Epoch [2/5], Train loss: 0.2492, Validation loss: 0.1494\n",
            "Epoch [3/5], Train loss: 0.0760, Validation loss: 0.1776\n",
            "Epoch [4/5], Train loss: 0.0447, Validation loss: 0.1773\n",
            "Epoch [5/5], Train loss: 0.0499, Validation loss: 0.1788\n"
          ]
        }
      ],
      "source": [
        "early_stopping_steps = 10 ## TO COMPLETE\n",
        "min_validation_loss = float('inf') ## TO COMPLETE\n",
        "#The first time the validation loss is computed it will be considered the lowest validation loss seen so far.\n",
        "nb_steps_where_test_loss_did_not_decrease = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "         # original shape [batch_size, 1, 28, 28], resized to [batch_size, 784]\n",
        "         images = images.reshape(-1, 28*28)\n",
        "         # Forward pass\n",
        "         outputs = model(images)\n",
        "         loss = loss_function(outputs, labels)\n",
        "         # Backward and optimize\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "    # validation loss for early stopping\n",
        "    nb_steps_where_test_loss_did_not_decrease += 1\n",
        "    if (nb_steps_where_test_loss_did_not_decrease > early_stopping_steps):\n",
        "        print('The test loss no longer decreases... STOP')\n",
        "        break\n",
        "    for j, (validation_images, validation_labels) in enumerate(validation_loader):\n",
        "         validation_loss = loss_function(model(validation_images.reshape(-1, 28*28)),validation_labels)\n",
        "    if (validation_loss < min_validation_loss):\n",
        "        min_validation_loss = validation_loss\n",
        "        nb_steps_where_test_loss_did_not_decrease = 0\n",
        "        print(f'-- Better model // saving')\n",
        "        torch.save(model, 'best_model')\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {loss.item():.4f}, Validation loss: {validation_loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyIBAAq7qoYv"
      },
      "source": [
        "We can then test the quality of the predictions made by the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzbPJKYgqoYw",
        "outputId": "4555282a-9925-47ac-ac0a-b601934de748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 95.69 %\n"
          ]
        }
      ],
      "source": [
        "del model\n",
        "model = torch.load('best_model')\n",
        "\n",
        "# no gradient needed for evaluation\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = 100.0 * n_correct / n_samples\n",
        "print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*So I can get an accuracy of 0.9568*"
      ],
      "metadata": {
        "id": "4Bfd_UvBSU_y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAf32ISLqoYw"
      },
      "source": [
        "**Question 2.** Try to improve the performance by various means (adding an extra hidden layer, regularizing with dropout, changing the optimization algorithm, etc). What is the best test accuracy you can achieve?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.l3 = nn.Linear(hidden_size2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.l3(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "HpaRZIearelW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w0aRAMDqoYx"
      },
      "outputs": [],
      "source": [
        "#--- construction of the model: from input_size to num_classes with one hidden layer ---\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "hidden_size1 = 100 ## TO COMPLETE\n",
        "hidden_size2 = 100 ## TO COMPLETE\n",
        "model = NeuralNet(input_size, hidden_size1, hidden_size2, num_classes)\n",
        "\n",
        "#--- Loss and optimizer ---\n",
        "num_epochs = 5 ## TO COMPLETE\n",
        "batch_size = 32 ## TO COMPLETE\n",
        "learning_rate = 0.01 ## TO COMPLETE\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) #change the optimization algorithm from Adam to SGD\n",
        "\n",
        "#--- data ---\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=validation_length,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=test_dataset.data.shape[0],shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_steps = 10 ## TO COMPLETE\n",
        "min_validation_loss = float('inf') ## TO COMPLETE\n",
        "#The first time the validation loss is computed it will be considered the lowest validation loss seen so far.\n",
        "nb_steps_where_test_loss_did_not_decrease = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "         # original shape [batch_size, 1, 28, 28], resized to [batch_size, 784]\n",
        "         images = images.reshape(-1, 28*28)\n",
        "         # Forward pass\n",
        "         outputs = model(images)\n",
        "         loss = loss_function(outputs, labels)\n",
        "         # Backward and optimize\n",
        "         optimizer.zero_grad()\n",
        "         loss.backward()\n",
        "         optimizer.step()\n",
        "    # validation loss for early stopping\n",
        "    nb_steps_where_test_loss_did_not_decrease += 1\n",
        "    if (nb_steps_where_test_loss_did_not_decrease > early_stopping_steps):\n",
        "        print('The test loss no longer decreases... STOP')\n",
        "        break\n",
        "    for j, (validation_images, validation_labels) in enumerate(validation_loader):\n",
        "         validation_loss = loss_function(model(validation_images.reshape(-1, 28*28)),validation_labels)\n",
        "    if (validation_loss < min_validation_loss):\n",
        "        min_validation_loss = validation_loss\n",
        "        nb_steps_where_test_loss_did_not_decrease = 0\n",
        "        print(f'-- Better model // saving')\n",
        "        torch.save(model, 'best_model')\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Train loss: {loss.item():.4f}, Validation loss: {validation_loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhDhD5faqXtU",
        "outputId": "8a1e4ab2-271c-44ac-c8fb-8d6a62f4bf41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Better model // saving\n",
            "Epoch [1/5], Train loss: 0.0736, Validation loss: 0.1764\n",
            "-- Better model // saving\n",
            "Epoch [2/5], Train loss: 0.0465, Validation loss: 0.1219\n",
            "-- Better model // saving\n",
            "Epoch [3/5], Train loss: 0.0044, Validation loss: 0.1093\n",
            "-- Better model // saving\n",
            "Epoch [4/5], Train loss: 0.0218, Validation loss: 0.0986\n",
            "-- Better model // saving\n",
            "Epoch [5/5], Train loss: 0.0095, Validation loss: 0.0887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model = torch.load('best_model')\n",
        "\n",
        "# no gradient needed for evaluation\n",
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28)\n",
        "        outputs = model(images)\n",
        "        # max returns (value ,index)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        n_samples += labels.size(0)\n",
        "        n_correct += (predicted == labels).sum().item()\n",
        "\n",
        "acc = 100.0 * n_correct / n_samples\n",
        "print(f'Accuracy of the network on the 10000 test images: {acc} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf385IKNqmJ6",
        "outputId": "eaad56aa-116b-49d4-a734-3527c9375efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 97.22 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Just changing the optimizer to SGD increased the accuracy to 0.9705.*\n",
        "\n",
        "*With the change and the add of an extra hidden layer: Accuracy=0.9724*"
      ],
      "metadata": {
        "id": "Ek0wfudXsJjK"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}